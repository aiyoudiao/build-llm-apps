## Day 5-1 总结

主要是在「怎么优化 RAG 效果」这件事上，从最基础的 Embedding 模型选择，到 RAG 流程的完整实现，再到核心的切片策略优化，最后进阶到多模态 RAG（处理文本 + 图片）。大概可以分成四条线：Embedding 模型、PDF 知识库构建、切片策略、以及多模态助手。

### 记忆卡片
- **Embedding 模型**：使用 BGE-M3 和 GTE-Qwen2 等本地模型将文本转化为向量，理解向量相似度计算（点积/余弦相似度）。
- **RAG 全流程**：PDF 解析 -> 文本切片 (Chunking) -> 向量化 (Embedding) -> 存入向量库 (FAISS) -> 检索 (Retrieval) -> 大模型生成 (Generation)。
- **切片策略**：不仅仅是按字符切分，还有“句子语义切片”、“LLM 语义切片”、“Markdown 层次切片”和“滑动窗口”等多种策略，目的是让切出来的块语义更完整。
- **多模态 RAG**：除了处理文本，还能处理图片。用 OCR 提取文字，用 CLIP 提取图片特征，实现“以文搜图”和“基于图文回答”。
- **工具链**：LangChain (框架), PyPDF2 (PDF解析), FAISS (向量库), DashScope (通义千问 API), ModelScope (模型下载)。

### 理解
- **Embedding 部分**：
  - `1.beg-使用本地模型.py`：下载并加载 BGE-M3 模型，把句子变成向量，算一下相似度。
  - `2.gte-qwen2-只用本地模型.py`：尝试了更强的 GTE-Qwen2 模型，学会了怎么处理 `trust_remote_code` 和依赖问题。
  - `3.gte-qwen2-深入原理.py`：手写 Pooling 和归一化，深入理解 Embedding 计算原理。
- **PDF 知识库 (Chat PDF)**：
  - `2.chat-pdf-faiss/将PDF变成RAG知识库.py`：这是一个标准的 RAG demo。重点是把 PDF 里的字读出来，切成小块，存进 FAISS 向量库。用户问问题时，先去库里找相关的块，再把这些块扔给大模型去回答。还做了“来源溯源”，告诉你答案是从第几页找到的。
- **切片策略 (RAG Slice)**：
  - 这一部分是在探讨“怎么切分文本效果最好”。
  - `1.固定长度切片.py`：最简单，按字数硬切，可能会把句子切断。
  - `2.句子语义切片.py`：聪明一点，按句号、感叹号切，保证句子的完整性。
  - `3.LLM语义切片.py` & `4.markdown层次切片.py`：更高级的玩法，利用 LLM 或文档结构来切分。
  - `5.滑动窗口切换.py`：窗口滑着走，重叠度高，适合短文本匹配。
  - `6.Qwen-VL图像理解.py`：尝试用视觉大模型（Qwen-VL）来看图说话，为多模态做准备。
- **多模态助手 (Disney RAG)**：
  - `4.disney-RAG-assistant/multimodal-bot.py`：这是一个综合大作业。
  - **知识库构建**：不仅读 Word 文档，还扫描图片文件夹。
  - **图片处理**：用 Tesseract OCR 读图上的字，用 CLIP 模型提取图片的“视觉特征”。
  - **双路检索**：用户问问题，既在文本向量库里找答案，也在图片向量库里找相关的图。
  - **增量更新**：通过计算文件哈希值 (MD5)，如果文件没变就不重新建库，省时省力。
